Q：jvm运行时数据区。
===
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_data_zone.png)
### 程序计数器
>程序计数器是一块较小的内存空间，每个线程私有，作为当前线程所执行的字节码行号指示器。且如果执行java方法计数器记录，如果执行native方法则计数器值为空。
### java虚拟机栈
>用于描述java方法执行的内存模型，每个方法执行的时候创建一个栈帧，用于存储局部变量，操作数栈，动态链接，方法出口信息等。每一个方法调用至完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。局部变量可以存储八大基本数据类型及对象引用类型。
### 本地方法栈
>相对于java虚拟机栈，本栈调用的方法为native方法服务。
### java堆
>java虚拟机管理的最大一块内存，所有线程共享，在虚拟机启动的时候创建，只用来存放对象实例。也是GC关注的主要区域。可以分为新生代（Eden，From survivor， To Survivor）和老年代。堆可以处于物理上不连续的内存空间中，只要逻辑上连续即可。

![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_heap_model.png)

### 方法区
>所有线程共享，存放虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。
### 运行时常量池
>这部分内容在来加载后进入方法区。

### 直接内存
>是一种堆外内存，通过一个存储在java堆中的DirecByteBuffer对象作为这个内存的引用进行操作，是由native函数库直接分配的内存，这样可以减少java堆和native堆之间来回复制数据。

Q：对象创建
===
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_create_object.png)
创建的关键字为new。当虚拟机遇到一个new指令时，会进行一下操作：
1. 检查指令参数是否在常量池中可以定位到一个类的符号引用，并检查所代表的类是否已经被加载、解析和初始化过，如果没有则先执行相应的类加载过程。
2. 为新生对象分配内存。有两种方式：指正碰撞（堆内存绝对规整，通过移动分界指针分配内存），空闲列表（堆内存不规整，维护一个列表，记录内存可用地方）。堆是否规整由所采用的垃圾收集器是否带有压缩整理功能决定。由于堆是线程共享，所以需要考虑分配内存是，多线程问题。一是通过CAS加失败重试的方法保证分配内存空间的操作的原子性。二是通过对每个线程预先分配堆内存的缓冲区。
3. 对分配完成后的内存空间进行初始化为零值。
4. 虚拟机对对象进行必要设置，主要设置对象内存头的信息。
5. 虚拟机已经产生一个新的对象，最后执行程序编写中的init方法。

Q：对象的内存布局
===
对象在内存中存储的布局分为三块区域：对象头，实例数据，对齐填充。
对象头：分为两部分，第一部分用于存储对象自身的运行时数据，如哈希吗，GC分代年龄，锁状态等。第二部分是类型指针，即对象指向它的类元数据的指针。
实例数据：对象真正存储的有效信息，即程序中定义的各种类型字段内容。无论父类继承还是子类定义，都记录。
对齐填充：自动内存管理系统要求对象起始地址必须是8字节的倍数。

Q：对象的访问定位
===
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_obj_visit.png)
栈中存放的引用类型，只规定了一个指向对象的引用，具体如何定位，由虚拟机实现，主要有两种方式：使用句柄，直接指针。（句柄可以理解为指向指针的指针，维护指向对象的指针的变化，对象的句柄本身不变化）

Q：对象是否可回收
===
1. 引用计数算法：通过计数器，引用+1，失效-1，为0时认为不可用。简单高效，但是很难解决对象之间相互循环引用的问题。
2. 可达性分析算法：通过GC Roots对象作为起点，向下搜索形成引用链，如果一个对象到GC Roots之间没有引用链，则认为不可用。GC 
3. Roots包括：虚拟机栈中引用的对象，方法去中类静态属性引用的对象，方法去中常量引用的对象，native方法引用的对象。
4. 可达性分析算法需要至少经历两次标记过程，如果不可达则进行标记并进行筛选（筛选条件为是否有必要执行finalize()方法，当没有重写或已经被虚拟机调用了则认为是没有必要执行），对于需要执行的情况下，则在finalize()方法中可以重新与引用链上的任意对象项链，将会被移除出即将回收的集合，从而避免回收。需要注意的是，任何一个对象的finalize方法只会被系统自动调用一次。不建议这么使用finalize方法，甚至不建议在程序中使用该方法。

Q：引用
===
+ 强引用：例如Object obj = new Object()，强引用存在，则永远不回收。
+ 软引用：通过jdk中SoftReference实现，在发生内存溢出异常之前，进行二次回收。
+ 弱引用：通过jdk中WeakReference实现，只生存到下次垃圾收集发生之前。无论内存是否足够，垃圾收集发生后都回收。
+ 虚引用：通过jdk中PhantomReference实现，无发通过该引用获取一个对象实例，唯一的目的是用来在回收时收到一条系统消息。

Q：垃圾收集算法
===
1. 标记-清除算法
先标记后清除，标记的时候会停顿所有线程。最基础的收集算法，但是效率较低，并且回收后的内存空间不连续，存在大连不连续内存碎片。影响分配大对象。
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_gc_mark_sweep.png)
2. 复制算法
内存分为两部分，运行时使用其中一部分，当发起回收时，将存活对象复制到空白内存部分，并清除原先使用的部分。简单高效，空间连续。但是损失内存空间。
经IBM研究新生代98%的对象朝生夕死，所以将new内存分为8:1:1（Eden，From Survivor，To Survivor），每次使用Eden和From Survivor，回收时将存活的对象放到To Survivor上（据说清理后会将To与From交换，保证每次GC后使用的都是Eden和From，回收复制时放置的地方总是To），并清理其他部分。如果Survivor空间不足则需要依赖old部分进行分配担保。
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_gc_copying.png)
3. 标记-整理算法
在标记-清除算法基础上，在标记阶段后不直接清除，而是让所有存活对象都向一端移动（整理），然后清除掉整理边界以外的内存。
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_gc_mark_compact.png)
4. 分代收集算法
是一种针对将内存分为不同区域，各个区域使用自己合适的收集算法，通常java堆分为new和old（新生代，老年代），new使用复制算法，old使用标记-xx算法。


Q：HotSpot的算法实现
===
1. 枚举根节点
为可达性分析做准备，必须停顿所有java执行线程，通过一组成为OopMap的数据结构得知哪些地方存放着对象引用。
2. 安全点
对于达到安全点的地方记录指令并存入OopMap中。通常有抢先式中断（基本已弃用）和主动式中断。抢先式中断：GC发生，首先发所有线程中断，发现中断的地方不在安全点则回复线程并跑到安全点。主动式中断，设置一个标志位，当需要中断时修改标志位，并让线程主动轮询标志位，在中断。标志位本身与安全点重合。
3. 安全区域
对于处于sleep和block的线程无法响应jvm中断请求，这些线程会进入安全区域，安全区域线程可以GC。当离开安全区域时，需要检查系统是否完成枚举根节点或GC，如果完成则线程继续执行，否则等待。


Q：垃圾收集器
===
HotSpot垃圾收集器关系图：
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_generation.png)
#### Serial：
>最基本，发展历史最悠久的单线程收集器，运行时必须暂停其他所有的工作线程，直到收集结束。但是简单高效，由于单线程没有线程交互开销，从而获得最高的单线程收集效率。
#### ParNew：
>与Serial基本相同，只是拥有了多线程收集能力。
#### Parallel Scavenge：
>设计出发点与其他收集器较为不同，它的目标是达到一个可控制的吞吐量，即CPU用于运行用户代码的时间与CPU总消耗时间的比值（其实就是从整体的视角来看，降低收集的停顿总时间，从而提高CPU使用率）。除此之外，它还拥有GC自适应的调节策略，动态调整参数以提供最适合的停顿时间或吞吐量。从多线程和回收算法来看与ParNew并无不同。
#### Serial Old：
>Serial的老年代版本，同样是单线程，用于搭配Paralle Scavenge和为CMS提供后备方案。但是它使用的标记-整理算法。
#### Parallel Old：
>Parallel Scavenge的老年代版本，多线程。主要是为了配合Parallel Scavenge，替代Serial Old。从而提供一个吞吐量优先的收集器组合。但是它使用的标记-整理算法。
#### CMS：
>是一种获取最短停顿时间的收集器，多用于互联网或者BS系统的服务端，重视响应速度，也是第一个并发收集器。基于标记-清除算法，分为四个阶段（初始标记，并发标记，重新标记，并发清除）。缺点在于对CPU资源敏感，无法处理浮动垃圾（即在并发清理阶段用户线程运行时出现的垃圾，并且存在预留空间不足而回收失败需要启用Serial Old回收垃圾），标记-清除算法的通病产生大量不连续空间碎片。
#### G1：
+ 并行与并发：多线程可以充分利用CPU性能，且GC时java程序仍旧可运行。
+ 分代收集：可以不需要配合其它收集器，自身可以采用不同的方式处理各个阶段的对象。
+ 空间整合：不会产生内存碎片。
+ 可预测的停顿：实时java（RTSJ）的一个特征，可以在指定M毫秒时间段内回收时间不超过N毫秒。
>java内存布局与其他收集器有很大区别，将整个java堆划分为多个大小相同的独立区域（region），新生代和老年代已经不是物理隔离，都是一部分可以不连续的region的集合。G1跟踪每个region的回收价值，在后台维护一个优先列表，回收价值最大的region。
>存在Remembered Set维护操作，用来保证回收时做可达性分析判断时不需要对整个java堆进行扫描。除去该操作G1共分为以下几步：初始标记，并发标记，最终标记，筛选回收。
#### GC日志：
>每个收集器的日志格式不一样，但虚拟机设计时尽量将各个收集器的日志维持了一定的共性。日志格式大致为：
+ 100.661 : [Full GC [Tenured : 0K->210(10240K), 0.149142 secs] 4603K->210K(19456K), [Perm : 2999K->2999K(21245K)], 0.0150007 secs] [Times:user=0.01 sys=0.00, real=0.02 secs]
+ 时间：[停顿类型 [GC发生区域 ： GC前内存已使用容量->GC后内存已使用容量(内存总容量)] GC前java堆已用容量->GC后java堆已用容量(堆总容量), 内存区域GC所占用时间][具体时间：用户态消耗cpu时间，内核态消耗cpu时间，操作从开始到结束所经过的墙钟时间] 
#### 其他部分
+ 停顿时间越短就越适合需要与用户交互的程序。而高吞吐量则高效利用CPU适合多后台运算少交互的任务。
+ 自动内存管理主要为对象分配内存和回收分配给对象的内存。对象的内存分配，大方向来看就是在堆上分配，且主要就是在Eden。这里介绍下：新生代GC(Minor GC)频分但回收速度快。老年代GC(Major GC/Full GC)速度较于Minor GC慢10倍以上。
+ 大对象：需要大量连续内存空间的java对象，最典型的大对象就是那种很长的字符串及数组。通常直接进入老年代。
+ 通过对象年龄计数器可以判断长期存活的对象是否将进入老年代，通常在Eden生成的对象在第一次Minor GC后仍然存活并被Survivor容纳的话将被移动到Survivor中并加一年龄。默认15岁进入老年代。当然也可以动态对象年龄判断，如果在Survior中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象直接进入老年代。
+ 空间分配担保：主要由于新生代采用复制算法，在某些情况下可能会空间不足，需要老年代担保才能进行Minor GC 。如果担保后仍然空间不足，那么需要进行一次Full GC 。通过前一次回收晋升老年代对象的容量的平均值作为经验，来判断是否担保成功。
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_serial&serial_old.png)
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_parnew&serial_old.png)
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_parallel_scavenge&parallel_old.png)
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_cms.png)
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_g1.png)

  
Q：Java内存模型与线程
===
+ Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。变量包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不被共享。
+ 线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝（事实上，只拷贝在线程中有可能使用到的字段，不会把整个对象拷贝一次）。
+ 线程间变量的传递均需要通过主内存来完成。线程自己的变量均在自己的工作内存中进行，不能直接读写主内存变量，其中volatile修饰的变量，同样拥有工作内存的拷贝，但由于其特殊的操作顺序，可以保证可见性，所以看起来如同直接在主内存中读写访问。
+ 简单的说，主内存主要对应Java堆中的对象实例数据部分，工作内存则对应于虚拟机栈中的部分区域。
+ 内存模型中有八大操作，每个操作都是具有原子性：lock，unlock，read，load，use，assign，store，write。
+ volatile具有可见性和禁止指令重排序优化的特性，但不能保证并发下线程安全。
+ 并发过程中的三大特性：原子性，可见性，有序性。
+ 先行发生原则：判断数据是否存在竞争，线程是否安全的主要依据。
+ 线程的实现：内核线程，用户线程，用户线程及轻量级进程混合。
+ 线程调度：协同式线程调度，抢占式线程调度。
+ 线程状态：新建，运行，无限期等待和限期等待，阻塞，结束。


Q：线程安全与锁优化
===
+ 当多个线程访问同一个对象时，如果不考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的。
+ 通常有五种级别的线程安全：不可变，绝对线程安全，相对线程安全，线程兼容，线程对立。
+ 线程安全的实现方式：互斥同步（synchronized和reentrantlock），非阻塞同步（CAS等），无同步方案（可重用代码和线程本地存储，本身无共享数据）
+ 锁优化：为了线程之间更高效的共享数据，解决竞争问题。
+ 自旋锁与自适应自旋：由于挂起线程和恢复线程需要在内核态完成，很浪费性能，并且共享数据的锁定通常持续时间很短，所以通过减少不必要的挂起和恢复，通过让线程执行一个忙循环（自旋），使线程不放弃cpu占用时间，让后续线程等待锁。自旋等待不等于代替阻塞。自旋等待的效果取决于锁占用的时间是否很短，时间短效果好。自适应自旋是自旋的升级版，通过前一个同一个锁上的自旋时间及锁拥有者的状态自动调整自旋时间。
+ 锁消除：虚拟机即时编译器运行时通过逃逸分析的数据支持，检测到不可能存在共享的数据竞争的锁，从而进行消除。例如方法参数为多个string，方法体为参数相加，编译器会自动优化为stringbuffer的append，所以造成了无用的锁。
+ 锁粗化：对一个对象循环进行连续同步操作，可以把加锁同步的范围扩大到整个操作序列的外部。
+ 轻量级锁：在考虑绝大部分锁，在整个同步周期内不存在竞争才能提升性能。通过对象的内存布局，CAS等来操作，如果竞争则开销更大。不能代替重量级锁。
+ 偏向锁：偏向第一个持有该锁的线程，并在该锁没有被其他线程获得的情况下，持有该偏向锁的线程不需要进行同步。如果获取该锁，则偏向模式结束，恢复到未锁定或轻量级锁状态。
+ 锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_biased_lock.png)
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jvm_light_lock.png)

|锁      |优点     |缺点      |适用场景|
|--------|---------|---------|---------|
|偏向锁   |加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距|如果线程间存在锁竞争，会带来额外的锁撤销的消耗|适用于只有一个线程访问同步块场景|
|轻量级锁 |竞争的线程不会阻塞，提高了程序的响应速度|如果始终得不到锁竞争的线程使用自旋会消耗CPU|追求响应时间,锁占用时间很短|
|重量级锁 |线程竞争不使用自旋，不会消耗CPU|线程阻塞，响应时间缓慢|追求吞吐量,锁占用时间较长|



Q:jdk源码（集合）。
=== 
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jdk_collection.png)
![Image text](https://github.com/IceDarron/Note/blob/master/Image/jdk_LinkedHash.png)
+ Iterator
>java.util.Iterator接口主要定义了遍历集合对象的方法，通过迭代器模式，创建迭代器来遍历各种集合，每个集合中都有具体的实现。通过迭代器遍历时，在多线程下存在遍历过程中，另一个线程修改集合，这时候通过fast-fail机制可以抛出异常。

+ Collection
>The root interface in the <i>collection hierarchy</i>.  A collection represents a group of objects, known as its <i>elements</i>.  Some
 collections allow duplicate elements and others do not.  Some are ordered and others unordered.  The JDK does not provide any  <i>direct</i> implementations of this interface: it provides implementations of more specific subinterfaces like <tt>Set</tt> and  <tt>List</tt>.  This interface is typically used to pass collections around and manipulate them where maximum generality is desired.

+ List
>具体实现类：ArrayList（数组），Vector（数组），LinkedList（双向链表），Stack（数组）

+ Set
>具体实现类：HashSet（散列表HashMap），TreeSet（二叉树），LinkedHashSet（LinkedHashMap通过继承HashSet并使用它的构造函数实现）
TreeSet 是一个有序的集合，它的作用是提供有序的Set集合。它继承于AbstractSet抽象类，实现了NavigableSet<E>, Cloneable, java.io.Serializable接口。
TreeSet 继承于AbstractSet，所以它是一个Set集合，具有Set的属性和方法。
TreeSet 实现了NavigableSet接口，意味着它支持一系列的导航方法。比如查找与指定目标最匹配项。
TreeSet 实现了Cloneable接口，意味着它能被克隆。
TreeSet 实现了java.io.Serializable接口，意味着它支持序列化。
TreeSet是基于TreeMap实现的。TreeSet中的元素支持2种排序方式：自然排序 或者 根据创建TreeSet 时提供的 Comparator 进行排序。这取决于使用的构造方法。

+ Queue
>具体实现类：LinkedBlockingQueue（单向链表实现的阻塞队列），PriorityQueue（数组），ArrayDeque（数组，可以实现队列或栈）
Queue本身是一种先入先出的模型(FIFO)。
Deque是Queue的子接口，是一种增强，代表一个双端队列。同时Deque不仅可以作为双端队列使用，而且可以被当成栈来使用，所以可以使用出栈，入栈的方法。

+ Map
>具体实现类：HashMap（散列表），TreeMap（红黑树数据结构），LinkedHashMap（散列表+双向链表）
>TreeMap 是一个有序的key-value集合，它是通过红黑树实现的。
TreeMap 继承于AbstractMap，所以它是一个Map，即一个key-value集合。
TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合。
TreeMap 实现了Cloneable接口，意味着它能被克隆。
TreeMap 实现了java.io.Serializable接口，意味着它支持序列化。
TreeMap基于红黑树（Red-Black tree）实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。
TreeMap的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n) 。
另外，TreeMap是非同步的。 它的iterator 方法返回的迭代器是fail-fastl的。
TreeMap的本质是R-B Tree(红黑树)，它包含几个重要的成员变量： root, size, comparator。
root是红黑数的根节点。它是Entry类型，Entry是红黑数的节点，它包含了红黑数的6个基本组成成分：key(键)、value(值)、left(左孩子)、right(右孩子)、parent(父节点)、color(颜色)。Entry节点根据key进行排序，Entry节点包含的内容为value。红黑数排序时，根据Entry中的key进行排序；Entry中的key比较大小是根据比较器comparator来进行判断的。size是红黑数中节点的个数。

+ Collections&Arrays
>提供集合和数组之间的转换，排序，最大值等方法。


Q：java源码（原子类java.util.concurrent.atomic）
===
>这个包提供了一系列原子类。这些类可以保证多线程环境下，当某个线程在执行atomic的方法时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由JVM从等待队列中选择一个线程执行。Atomic类在软件层面上是非阻塞的，它的原子性其实是在硬件层面上借助相关的指令来保证的。
#### Atomic包中的类可以分成4组：
+ AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference
+ AtomicIntegerArray，AtomicLongArray
+ AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater
+ AtomicMarkableReference，AtomicStampedReference，AtomicReferenceArray
```java
public final int incrementAndGet() {  
    for (;;) {  
        int current = get();  
        int next = current + 1;  
        if (compareAndSet(current, next))  
            return next;  
    }  
}  
```
>方法中采用了CAS操作，每次从内存中读取数据然后将此数据和+1后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。而compareAndSet利用JNI来完成CPU指令的操作。整体的过程就是这样子的，利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法。

#### CAS的优缺点
>CAS由于是在硬件层面保证的原子性，不会锁住当前线程，它的效率是很高的。 
CAS虽然很高效的实现了原子操作，但是它依然存在三个问题。
+ ABA问题。CAS在操作值的时候检查值是否已经变化，没有变化的情况下才会进行更新。但是如果一个值原来是A，变成B，又变成A，那么CAS进行检查时会认为这个值没有变化，但是实际上却变化了。ABA问题的解决方法是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就变成1A-2B－3A。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。
+ 并发越高，失败的次数会越多，CAS如果长时间不成功，会极大的增加CPU的开销。因此CAS不适合竞争十分频繁的场景。
+ 只能保证一个共享变量的原子操作。当对多个共享变量操作时，CAS就无法保证操作的原子性，这时就可以用锁，或者把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象的原子性，你可以把多个变量放在一个对象里来进行CAS操作。


Q：jdk源码（ConcurrentHashMap）
===
ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同部分进行的修改。ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的Hashtable，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。这里“按顺序”是很重要的，否则极有可能出现死锁，在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，但是，仅仅是将数组声明为final的并不保证数组成员也是final的，这需要实现上的保证。这可以确保不会出现死锁，因为获得锁的顺序是固定的。
#### 原理
>ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图：
![Image text](https://github.com/IceDarron/Note/blob/master/Image/ConcurrentHashMap_Segment.png)
>从图中可以看到，ConcurrentHashMap内部分为很多个Segment，每一个Segment拥有一把锁，然后每个Segment继承了ReentrantLock，表明每个segment都可以当做一个锁。这样对每个segment中的数据需要同步操作的话都是使用每个segment容器对象自身的锁来实现。只有对全局需要改变时锁定的是所有的segment。
ConcurrentHashMap中的HashEntry相对于HashMap中的Entry有一定的差异性：HashEntry中的value以及next都被volatile修饰，这样在多线程读写过程中能够保持它们的可见性。
#### 并发度
>并发度可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。ConcurrentHashMap默认的并发度为16，但用户也可以在构造函数中设置并发度。当用户设置并发度时，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。运行时通过将key的高n位（n = 32 – segmentShift）和并发度减1（segmentMask）做位与运算定位到所在的Segment。segmentShift与segmentMask都是在构造过程中根据concurrency level被相应的计算出来。
如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。
#### jdk8改进
+ TreeNode树节点类:另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。但是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。而且TreeNode在ConcurrentHashMap集成自Node类，而并非HashMap中的集成自LinkedHashMap.Entry<K,V>类，也就是说TreeNode带有next指针，这样做的目的是方便基于TreeBin的访问。
+ TreeBin:这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别。另外这个类还带有了读写锁。
+ 摒弃了Segment（锁段）的概念，而是启用了一种全新的方式实现,利用CAS算法。
+ 不采用segment而采用node，锁住node来实现减小锁粒度。
+ 使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。
+ 使用synchronized而不是ReentrantLock
#### key-value
+ ConcurrentHashMap中的key和value值都不能为null，HashMap中key可以为null，HashTable中key不能为null。
+ ConcurrentHashMap是线程安全的类并不能保证使用了ConcurrentHashMap的操作都是线程安全的！
+ ConcurrentHashMap的get操作不需要加锁，put操作需要加锁


Q：jdk源码（ReentrantLock）
===
![Image text](https://github.com/IceDarron/Note/blob/master/Image/reentrantLock_uml.png)
>ReentrantLock类在java.util.concurrent.locks包中，它的上一级的包java.util.concurrent主要是常用的并发控制类。
java.util.concurrent.lock 中的 Lock 框架是锁定的一个抽象，它允许把锁定的实现作为 Java 类，而不是作为语言的特性来实现。这就为 Lock 的多种实现留下了空间，各种实现可能有不同的调度算法、性能特性或者锁定语义。 ReentrantLock 类实现了 Lock ，它拥有与 synchronized 相同的并发性和内存语义，但是添加了类似轮询锁、定时锁等候和可中断锁等候的一些特性。此外，它还提供了在激烈争用情况下更佳的性能。（换句话说，当许多线程都想访问共享资源时，JVM 可以花更少的时候来调度线程，把更多时间用在执行线程上。）
ReentrantLock支持两种锁模式，公平锁和非公平锁。默认的实现是非公平的。


Q：消息队列MQ
===
>消息队列技术是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上,队列存储消息直到它们被应用程序读走。
通过消息队列，应用程序可独立地执行--它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。
在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。
消息队列为构造以同步或异步方式实现的分布式应用提供了松耦合方法。
消息队列的API调用被嵌入到新的或现存的应用中，通过消息发送到内存或基于磁盘的队列或从它读出而提供信息交换。
消息队列可用在应用中以执行多种功能，比如要求服务、交换信息或异步处理等。

#### MQ的通讯模式
+ 点对点通讯：点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。
+ 多点广播：MQ适用于不同类型的应用。其中重要的，也是正在发展中的是"多点广播"应用，即能够将消息发送到多个目标站点(Destination List)。可以使用一条MQ指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ将消息的一个复制版本和该系统上接收者的名单发送到目标MQ系统。目标MQ系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。
+ 发布/订阅(Publish/Subscribe)模式：发布/订阅功能使消息的分发可以突破目的队列地理指向的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅功能使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。在MQ家族产品中，MQ Event Broker是专门用于使用发布/订阅技术进行数据通讯的产品，它支持基于队列和直接基于TCP/IP两种方式的发布和订阅。
+ 群集(Cluster)：为了简化点对点通讯模式中的系统配置，MQ提供Cluster(群集)的解决方案。群集类似于一个域(Domain)，群集内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用群集(Cluster)通道与其它成员通讯，从而大大简化了系统配置。此外，群集中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性。


#### Kafka
![Image text](https://github.com/IceDarron/Note/blob/master/Image/kafka_topic.png)
>Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群机来提供实时的消费。
Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：
+ 通过磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。（文件追加的方式写入数据，过期的数据定期删除）
+ 高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。
+ 支持通过Kafka服务器和消费机集群来分区消息。
+ 支持Hadoop并行数据加载。
+ Broker:：Kafka集群包含一个或多个服务器，这种服务器被称为broker(代理)。
+ Topic：话题是特定类型的消息流。每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）
+ Partition：是物理上的概念，每个Topic包含一个或多个Partition.
+ Producer：负责发布消息到Kafka broker
+ Consumer：消息消费者，向Kafka broker读取消息的客户端。
+ Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。
+ 一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用。


#### RocketMQ
>世界上解决一个计算机问题最简单的方法：“恰好”不需要解决它！—— 沈询
>RocketMQ认为消息队列为了保持高吞吐，海量数据，低延迟，数据安全等，故在一些异常等小概率事件处理上保持不解决的态度，这些事件应当在消费端（业务逻辑）中处理。其实也就是设计模式中的单一职责原则，未来的技术或系统等，在性能不能从硬件上发生根本的变化时，将会功能越来越单一。
+ 顺序消息：在同一个分区（queue）下保持顺序，同一个分区下是FIFO。但是消息发送默认是采用轮训的方式发送到不同的分区。通过一个连续消息共用的id取模获取同一个queue（类似于桶的概念）。
+ 消息重复：RocketMQ不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。处理的两个方面：消费端处理消息的业务逻辑保持幂等性。保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。
+ 事务消息：大事务 = 小事务 + 异步。尽量不在消息队列中处理回滚等操作。
+ Producer如何发送消息：轮询某topic下的所有队列的方式来实现发送方的负载均衡。如果Producer发送消息失败，会自动重试，重试的策略：重试次数 < retryTimesWhenSendFailed（可配置）。总的耗时（包含重试n次的耗时） < sendMsgTimeout（发送消息时传入的参数）。同时满足上面两个条件后，Producer会选择另外一个队列发送消息。
+ 消息存储：RocketMQ的消息存储是由consume queue和commit log配合完成的。consume queue是消息的逻辑队列，相当于字典的目录，用来指定消息在物理文件commit log上的位置。
+ 消息订阅：RocketMQ消息订阅有两种模式，一种是Push模式，即MQServer主动向消费端推送；另外一种是Pull模式，即消费端在需要时，主动到MQServer拉取。但在具体实现时，Push和Pull模式都是采用消费端主动拉取的方式。
+ 定时消息
+ 消息的刷盘策略
+ 主动同步策略：同步双写、异步复制
+ 海量消息堆积能力
+ 高效通信


#### ActiveMQ     
>ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。
ActiveMQ特性如下：
+ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP
+ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)
+ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性
+ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上
+ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA
+ 支持通过JDBC和journal提供高速的消息持久化
+ 从设计上保证了高性能的集群，客户端-服务器，点对点
+ 支持Ajax
+ 支持与Axis的整合
+ 可以很容易得调用内嵌JMS provider，进行测试
