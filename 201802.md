Q:MapReduce
===
MapReduce其实是分治算法的一种实现，所谓分治算法就是“就是分而治之”，将大的问题分解为相同类型的子问题（最好具有相同的规模），对子问题进行求解，然后合并成大问题的解。MapReduce就是分治法的一种，将输入进行分片，然后交给不同的task进行处理，然后合并成最终的解。

![mapreduce模型](https://github.com/IceDarron/Note/blob/master/Image/mapReduce_model.png)

![mapreduce模型](https://github.com/IceDarron/Note/blob/master/Image/mapReduce_model0.png)

### Map阶段
首先是读数据，数据来源可能是文本文件，表格，MySQL数据库。这些数据通常是成千上万的文件（叫做shards），这些shards被当做一个逻辑输入源。然后Map阶段调用用户实现的函数，叫做Mapper，独立且并行的处理每个shard。对于每个shard，Mapper返回多个键值对，这是Map阶段的输出。

### Shuffle阶段
把键值对进行归类，也就是把所有相同的键的键值对归为一类。这个步骤的输出是不同的键和该键的对应的值的数据流。

### Reduce阶段
输入当然是shuffle的输出。然后Reduce阶段调用用户实现的函数，叫做Reducer，对每个不同的键和该键的对应的值的数据流进行独立、并行的处理。每个reducer遍历键对应的值，然后对值进行“置换”。这些置换通常指的的是值的聚合或者什么也不处理，然后把键值对写入数据库、表格或者文件中。

本问题仅简单介绍，相关资料如下：http://blog.csdn.net/u010725690/article/details/53893667


Q:布隆过滤器 bloom filter
===
布隆过滤器（Bloom Filter）是由布隆（Burton Howard Bloom）在1970年提出的。它实际上是由一个很长的二进制向量和一系列随机映射函数组成，布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率。

直观的说，bloom算法类似一个hash set，用来判断某个元素（key）是否在某个集合中。
和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。

### 算法步骤
1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数
2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0
3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1
4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。

![布隆过滤器结构](https://github.com/IceDarron/Note/blob/master/Image/bloom_filter.png)

### 优点
+ 不需要存储key，节省空间

### 缺点
+ 算法判断key在集合中时，有一定的概率key其实不在集合中
+ 无法删除

### Counting filters
> 基本的布隆过滤器不支持删除（Deletion）操作，但是 Counting filters 提供了一种可以不用重新构建布隆过滤器但却支持元素删除操作的方法。在Counting filters中原来的位数组中的每一位由 bit 扩展为 n-bit 计数器，实际上，基本的布隆过滤器可以看作是只有一位的计数器的Counting filters。原来的插入操作也被扩展为把 n-bit 的位计数器加1，查找操作即检查位数组非零即可，而删除操作定义为把位数组的相应位减1，但是该方法也有位的算术溢出问题，即某一位在多次删除操作后可能变成负值，所以位数组大小 m 需要充分大。另外一个问题是Counting filters不具备伸缩性，由于Counting filters不能扩展，所以需要保存的最大的元素个数需要提前知道。否则一旦插入的元素个数超过了位数组的容量，false positive的发生概率将会急剧增加。当然也有人提出了一种基于 D-left Hash 方法实现支持删除操作的布隆过滤器，同时空间效率也比Counting filters高。

### 较为成熟的实现
google的guava包中提供了BloomFilter类。


Q:倒排索引(inverted index)
===
倒排索引是实现“单词-文档矩阵”的一种具体存储形式，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成："单词词典"和"倒排文件"。其实倒排索引更恰当的应该翻译为倒置索引。
+ 单词词典(Lexicon)：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。
+ 倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。
+ 倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。

![倒排索引结构](https://github.com/IceDarron/Note/blob/master/Image/inverted_index.png)

例子：

![倒排索引例子0](https://github.com/IceDarron/Note/blob/master/Image/inverted_index_demo0.png)

![倒排索引例子1](https://github.com/IceDarron/Note/blob/master/Image/inverted_index_demo1.png)

+ 单词ID：记录每个单词的单词编号；
+ 单词：对应的单词；
+ 文档频率：代表文档集合中有多少个文档包含某个单词
+ 倒排列表：包含单词ID及其他必要信息
+ DocId：单词出现的文档id
+ TF：单词在某个文档中出现的次数
+ POS：单词在文档中出现的位置

> 以单词“加盟”为例，其单词编号为6，文档频率为3，代表整个文档集合中有三个文档包含这个单词，对应的倒排列表为{(2;1;<4>),(3;1;<7>),(5;1;<5>)}，含义是在文档2，3，5出现过这个单词，在每个文档的出现过1次，单词“加盟”在第一个文档的POS是4，即文档的第四个单词是“加盟”，其他的类似。


Q:假如有Thread1、Thread2、Thread3、Thread4四条线程分别统计C、D、E、F四个盘的大小，所有线程都统计完毕交给Thread5线程去做汇总，应当如何实现？
===
```java
package com.darron;

import java.util.concurrent.Callable;
import java.util.concurrent.CountDownLatch;

public class TestMultiThread {

    /**
     * 功能实现：核心类java.util.concurrent.CountDownLatch
     * CountDownLatch : 一个线程(或者多个)， 等待另外N个线程完成某个事情之后才能执行。本质上来讲就是一个计数器
     * 其核心还是AQS，在此不多赘述。
     */
    public static void main(String[] args) {

        CountDownLatch countDownLatch = new CountDownLatch(4); // 设置线程数
        ExecutorService executorService = Executors.newCachedThreadPool();//线程池

        Future future0 = executorService.submit(new Worker("c", countDownLatch));
        Future future1 = executorService.submit(new Worker("d", countDownLatch));
        Future future2 = executorService.submit(new Worker("e", countDownLatch));
        Future future3 = executorService.submit(new Worker("f", countDownLatch));

        try {
            countDownLatch.await(); // 等待所有磁盘计算完毕
            executorService.shutdown(); // 提交所有任务
            int total = (int) future0.get() + (int) future1.get() + (int) future2.get() + (int) future3.get();
            System.out.println(total);
        } catch (Exception e) {
            e.printStackTrace();
        }

    }

    // 实现Callable主要是为了能获取返回值
    public static class Worker implements Callable {

        private String cdName;

        private int cdCapacity;

        private CountDownLatch countDownLatch;

        public Worker() {
        }

        public Worker(String cdName, CountDownLatch countDownLatch) {
            this.cdName = cdName;
            this.countDownLatch = countDownLatch;
        }

        @Override
        public Object call() throws Exception {
            System.out.println("start calculate " + cdName);
            cdCapacity = cdName.charAt(0); // 模拟计算磁盘空间大小
            System.out.println("end calculate " + cdName + "capacity " + cdCapacity);
            countDownLatch.countDown(); // 计数器减一
            return cdCapacity;
        }
    }
}
```


Q:Java并发编程(Executor框架)
===
Eexecutor作为灵活且强大的异步执行框架，其支持多种不同类型的任务执行策略，提供了一种标准的方法将任务的提交过程和执行过程解耦开发，基于生产者-消费者模式，其提交任务的线程相当于生产者，执行任务的线程相当于消费者，并用Runnable来表示任务，Executor的实现还提供了对生命周期的支持，以及统计信息收集，应用程序管理机制和性能监视等机制。

![Executor的UML图](https://github.com/IceDarron/Note/blob/master/Image/Executor_UML.png)

+ Executor：一个接口，其定义了一个接收Runnable对象的方法executor，其方法签名为executor(Runnable command),
+ ExecutorService：是一个比Executor使用更广泛的子类接口，其提供了生命周期管理的方法，以及可跟踪一个或多个异步任务执行状况返回Future的方法
+ AbstractExecutorService：ExecutorService执行方法的默认实现
+ ScheduledExecutorService：一个可定时调度任务的接口
+ ScheduledThreadPoolExecutor：ScheduledExecutorService的实现，一个可定时调度任务的线程池
+ ThreadPoolExecutor：线程池，可以通过调用Executors以静态工厂方式来创建线程池并返回一个ExecutorService对象

### Executor的生命周期
ExecutorService提供了管理Eecutor生命周期的方法，ExecutorService的生命周期包括了：运行  关闭和终止三种状态。

ExecutorService在初始化创建时处于运行状态。

shutdown方法等待提交的任务执行完成并不再接受新任务，在完成全部提交的任务后关闭

shutdownNow方法将强制终止所有运行中的任务并不再允许提交新任务

### ExecutorService 的submit（） 与execute（）区别 
+ 接收的参数不一样 submit（）可以接受runnable和callable  有返回值。execute（）接受runnable 无返回值
+ submit有返回值，而execute没有
+ submit方便Exception处理

### Executors
提供了一系列静态工厂方法用于创建各种线程池

### 通过Executors提供四种线程池
newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 

newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 

newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 

newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

### new Thread的弊端
+ 每次new Thread新建对象性能差。
+ 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。
+ 缺乏更多功能，如定时执行、定期执行、线程中断。
相比new Thread，Java提供的四种线程池的好处在于：
+ 重用存在的线程，减少对象创建、消亡的开销，性能佳。
+ 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。
+ 提供定时执行、定期执行、单线程、并发数控制等功能。


Q:同步/异步和阻塞/非阻塞的区别
===
### 同步、异步 
+ 概念：消息的通知机制
+ 解释：涉及到IO通知机制；所谓同步，就是发起调用后，被调用者处理消息，必须等处理完才直接返回结果，没处理完之前是不返回的，调用者主动等待结果；所谓异步，就是发起调用后，被调用者直接返回，但是并没有返回结果，等处理完消息后，通过状态、通知或者回调函数来通知调用者，调用者被动接收结果。
  
### 阻塞、非阻塞
+ 概念：程序等待调用结果时的状态
+ 解释：涉及到CPU线程调度；所谓阻塞，就是调用结果返回之前，该执行线程会被挂起，不释放CPU执行权，线程不能做其它事情，只能等待，只有等到调用结果返回了，才能接着往下执行；所谓非阻塞，就是在没有获取调用结果时，不是一直等待，线程可以往下执行，如果是同步的，通过轮询的方式检查有没有调用结果返回，如果是异步的，会通知回调。


Q:java中的锁
锁的概念：公平锁、非公平锁、自旋锁、可重入锁、偏向锁、轻量级锁、重量级锁、读写锁、互斥锁等待。

### 公平锁和非公平锁
公平锁是指多个线程在等待同一个锁时，必须按照申请锁的先后顺序来一次获得锁。
公平锁的好处是等待锁的线程不会饿死，但是整体效率相对低一些；
非公平锁的好处是整体效率相对高一些，但是有些线程可能会饿死或者说很早就在等待锁，但要等很久才会获得锁。
其中的原因是公平锁是严格按照请求所的顺序来排队获得锁的，而非公平锁时可以抢占的，即如果在某个时刻有线程需要获取锁，
而这个时候刚好锁可用，那么这个线程会直接抢占，而这时阻塞在等待队列的线程则不会被唤醒。
公平锁可以使用new ReentrantLock(true)实现。

### 自旋锁
Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，
这就需要从用户态转换到核心态中，因此状态装换需要耗费很多的处理器时间，
对于代码简单的同步块（如被synchronized修饰的getter()和setter()方法），状态转换消耗的时间有可能比用户代码执行的时间还要长。
虚拟机的开发团队注意到在许多应用上，共享数据的锁定状态只会持续很短的一段时间，为了这段时间取挂起和恢复现场并不值得。
如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下“，
但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。
为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。
自旋等待不能代替阻塞。自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，
因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，
反之，如果锁被占用的时间很长，那么自旋的线程只会拜拜浪费处理器资源。
因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，
就应当使用传统的方式去挂起线程了。
自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK6中已经变为默认开启，并且引入了自适应的自旋锁。
自适应意味着自旋的时间不在固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。
自旋是在轻量级锁中使用的，在重量级锁中，线程不使用自旋。
如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，
那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100次循环。
另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。

### 锁消除
锁消除是虚拟机JIT在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。
锁消除的主要判断依据是来源于逃逸分析的数据支持，如果判断在一段代码中，
堆上的所有数据都不会逃逸出去从而能被其他线程访问到，那就可以把他们当做栈上数据对待，认为他们是线程私有的，同步加锁自然就无需进行。

来看这样一个方法：
```java
    public String concatString(String s1, String s2, String s3)
    {
        StringBuffer sb = new StringBuffer();
        sb.append(s1);
        sb.append(s2);
        sb.append(s3);
        return sb.toString();
    }
```

可以知道StringBuffer 的append方法定义如下：
```java
    public synchronized StringBuffer append(StringBuffer sb) {
        super.append(sb);
        return this;
    }
```

也就是说在concatString()方法中涉及了同步操作。
但是可以观察到sb对象它的作用域被限制在方法的内部，也就是sb对象不会“逃逸”出去，其他线程无法访问。
因此，虽然这里有锁，但是可以被安全的消除，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。

### 锁粗化
原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制的尽量小——只在共享数据的实际作用域中才进行同步，
这样是为了使得需要同步的操作数量尽可能变小，如果存在锁禁止，那等待的线程也能尽快拿到锁。
大部分情况下，这些都是正确的。但是，如果一些列的联系操作都是同一个对象反复加上和解锁，
甚至加锁操作是出现在循环体中的，那么即使没有线程竞争，频繁地进行互斥同步操作也导致不必要的性能损耗。

举个案例，类似锁消除的concatString()方法。如果StringBuffer sb = new StringBuffer();
定义在方法体之外，那么就会有线程竞争，但是每个append()操作都对同一个对象反复加锁解锁，
那么虚拟机探测到有这样的情况的话，会把加锁同步的范围扩展到整个操作序列的外部，
即扩展到第一个append()操作之前和最后一个append()操作之后，这样的一个锁范围扩展的操作就称之为锁粗化。

### 可重入锁
可重入锁，也叫做递归锁，指的是同一线程外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。

在JAVA环境下 ReentrantLock 和synchronized 都是可重入锁。可重入锁最大的作用是避免死锁。

### 类锁和对象锁
类锁：在方法上加上static synchronized的锁，或者synchronized(xxx.class)的锁。

对象锁：非静态方法加锁，成员变量或this上加锁

### 偏向锁、轻量级锁和重量级锁
synchronized的偏向锁、轻量级锁以及重量级锁是通过Java对象头实现的。
Java对象的内存布局分为：对象头、实例数据和对齐填充，而对象头又可以分为”Mark Word”和类型指针klass。
”Mark Word”是关键，默认情况下，其存储对象的HashCode、分代年龄和锁标记位。

这里说的都是以HotSpot虚拟机为基准的。首先来看一下”Mark Word”的内容：

锁状态	存储内容	标志位
无锁	对象的hashCode、对象分代年龄、是否是偏向锁（0）	01
轻量级	指向栈中锁记录的指针	00
重量级	指向互斥量（重量级锁）的指针	10
GC标记	（空）	11
偏向锁	偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1）	01
注意到这里的无锁和偏向锁在”Mark Word”的倒数第三bit中分别采用0和1标记。


|锁状态  |存储内容                                                       |标志位  |
| ------- |---------------------------------------------------------------|-------:|
|无锁     |对象的hashCode、对象分代年龄、是否是偏向锁（0）                |01      |
|轻量级   |指向栈中锁记录的指针                                           |00      |
|重量级   |指向互斥量（重量级锁）的指针                                   |10      |
|GC标记   |（空）                                                         |11      |
|偏向锁   |偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1）        |01      |

偏向锁是JDK6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。

偏向锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要同步。
大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。

当锁对象第一次被线程获取的时候，线程使用CAS操作把这个锁的线程ID记录再对象Mark Word之中，同时置偏向标志位1。
以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需要简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。
如果测试成功，表示线程已经获得了锁。

如果线程使用CAS操作时失败则表示该锁对象上存在竞争并且这个时候另外一个线程获得偏向锁的所有权。
当到达全局安全点（safepoint，这个时间点上没有正在执行的字节码）时获得偏向锁的线程被挂起，
膨胀为轻量级锁（涉及Monitor Record，Lock Record相关操作，这里不展开），同时被撤销偏向锁的线程继续往下执行同步代码。

当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。

线程在执行同步块之前，JVM会先在当前线程的栈帧中创建用于存储锁记录(Lock Record)的空间，
并将对象头中的Mard Word复制到锁记录中，官方称为Displaced Mark Word。
然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。
如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
如果自旋失败则锁会膨胀成重量级锁。如果自旋成功则依然处于轻量级锁的状态。

轻量级锁的解锁过程也是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，
那就用CAS操作把对象当前的Mark Word和线程中赋值的Displaced Mark Word替换回来，
如果替换成功，整个同步过程就完成了，如果替换失败，就说明有其他线程尝试过获取该锁，
那就要在释放锁的同时，唤醒被挂起的线程。

轻量级锁提升程序同步性能的依据是：对于绝大部分的锁，在整个同步周期内都是不存在竞争的（区别于偏向锁）。
这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，
但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁比传统的重量级锁更慢。

整个synchronized锁流程如下：

+ 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁
+ 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1
+ 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。
+ 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁
+ 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
+ 如果自旋成功则依然处于轻量级状态。
+ 如果自旋失败，则升级为重量级锁。


### 悲观锁和乐观锁
悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 

乐观锁：假定不会发生并发冲突，只在提交操作时检测是否违反数据完整性。（使用版本号或者时间戳来配合实现）

### 共享锁和排它锁
共享锁：如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排它锁。获准共享锁的事务只能读数据，不能修改数据。
 
排它锁：如果事务T对数据A加上排它锁后，则其他事务不能再对A加任何类型的锁。获得排它锁的事务即能读数据又能修改数据。

### 读写锁
读写锁是一个资源能够被多个读线程访问，或者被一个写线程访问但不能同时存在读线程。
Java当中的读写锁通过ReentrantReadWriteLock实现。具体使用方法这里不展开。

### 互斥锁
所谓互斥锁就是指一次最多只能有一个线程持有的锁。在JDK中synchronized和JUC的Lock就是互斥锁。

### 无锁
要保证现场安全，并不是一定就要进行同步，两者没有因果关系。
同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，
因此会有一些代码天生就是线程安全的。

+ 无状态编程。无状态代码有一些共同的特征：不依赖于存储在对上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非无状态的方法等。可以参考Servlet。
+ 线程本地存储。可以参考ThreadLocal
+ volatile
+ CAS
+ 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

### 分段锁
ConcurrentHashMap中采用了分段锁

### 闭锁
闭锁是一种同步工具类，可以延迟线程的进度直到其到达终止状态。
闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过，
当到达结束状态时，这扇门会打开允许所有的线程通过。
当闭锁到达结束状态后，将不会再改变状态，因此这扇门将永远保持打开状态。
闭锁可以用来确保某些活动指导其他活动都完成后才继续执行。CountDownLatch就是一种灵活的闭锁实现。

### 死锁
死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，他们都将无法推进下去。
这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足一下4个条件：

+ 互斥条件：一个资源每次只能被一个进程使用。
+ 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
+ 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。
+ 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序做操作来避免死锁。

### 活锁
LiveLock是一种形式活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复执行相同的操作，而且总会失败。
活锁通常发送在处理事务消息的应用程序中：如果不能成功地处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头：
如果不能成功地处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头。
如果消息处理器在处理某种特定类型的消息时存在错误并导致它失败，那么每当这个消息从队列中取出并传递到存在错误的处理器时，
都会发生事务回滚。由于这条消息又被放回到队列开头，因此处理器将被反复调用，并返回相同的结果。


Q:java源码AQS(AbstractQueuedSynchronizer)
===
类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，
如常用的ReentrantLock/Semaphore/CountDownLatch...。

它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。
这里volatile是核心关键词，具体volatile的语义，在此不述。state的访问方式有三种:

+ getState()
+ setState()
+ compareAndSetState()

AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，
如Semaphore/CountDownLatch）。

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，
至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：

+ isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
+ tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
+ tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
+ tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
+ tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。

以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。
此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。
当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。
但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。

再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。
这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。
等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。

一般来说，自定义同步器要么是独占方法，要么是共享方式，
他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。
但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。


Q:Object类
===
Object类是所有Java类的祖先。每个类都使用 Object 作为超类。所有对象（包括数组）都实现这个类的方法。

+ Object() 默认构造方法
+ clone() 创建并返回此对象的一个副本。
+ equals(Object obj) 指示某个其他对象是否与此对象“相等”。
+ finalize() 当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。
+ getClass() 返回一个对象的运行时类。
+ hashCode() 返回该对象的哈希码值。
+ notify() 唤醒在此对象监视器上等待的单个线程。
+ notifyAll() 唤醒在此对象监视器上等待的所有线程。
+ toString() 返回该对象的字符串表示。
+ wait() 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。
+ wait(long timeout) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。
+ wait(long timeout, int nanos) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。


Q:XOR 加密简介
===
首先，需要知道逻辑运算中的一个概念，异或运算（XOR）。即定义：两个值相同时，返回false，否则返回true。也就是说，XOR可以用来判断两个值是否不同。
而XOR 运算有一个很奇妙的特点：如果对一个值连续做两次 XOR，会返回这个值本身。根据这个特点，使得它可以用于信息的加密。

### 完美保密性
美国数学家香农（Claude Shannon）将他的研究成果公开发表，证明了只要满足两个条件，XOR 加密是无法破解的。

+ key的长度大于等于message
+ key必须是一次性的，且每次都要随机产生

满足上面两个条件的key，叫做 one-time pad（缩写为OTP），意思是"一次性密码本"，因为以前这样的key都是印刷成密码本，每次使用的时候，必须从其中挑选key。


Q:Session机制
===
![session](https://github.com/IceDarron/Note/blob/master/Image/session_model.png)

假如浏览器A先访问Servlet1，这时候它创建了一个Session，ID号为110，然后Servlet1将这个ID号以Cookie的方式返回给浏览器A，
接着，如果浏览器A继续访问Servlet2，那么这个请求会带上Cookie值: JSESSIONID=110，
然后服务器根据浏览器A传递过来的ID号找到内存中的这个Session。 
这时候假如浏览器B来访问Servlet1了，它的请求并没有带上 JSESSIONID这个Cookie值，
由于它也要使用Session，所以服务器会新创建一个Session，ID号为119，并将这个ID号以Cookie的方式返回给浏览器B。之后的过程就同A了。


Q:Cookie机制
===
当用户使用浏览器访问一个支持Cookie的网站的时候，用户会提供包括用户名在内的个人信息并且提交至服务器；
接着，服务器在向客户端回传相应的超文本的同时也会发回这些个人信息，当然这些信息并不是存放在HTTP响应体（Response Body）中的，
而是存放于HTTP响应头（Response Header）；当客户端浏览器接收到来自服务器的响应之后，浏览器会将这些信息存放在一个统一的位置，
对于Windows操作系统而言，我们可以从： [系统盘]:\Documents and Settings[用户名]\Cookies目录中找到存储的Cookie；
自此，客户端再向服务器发送请求的时候，都会把相应的Cookie再次发回至服务器。
而这次，Cookie信息则存放在HTTP请求头（Request Header）了。
有了Cookie这样的技术实现，服务器在接收到来自客户端浏览器的请求之后，就能够通过分析存放于请求头的Cookie得到客户端特有的信息，
从而动态生成与该客户端相对应的内容。


Q:分布式Session的几种实现方式
===